{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc176254-cc54-4624-b8b8-1b1f36388b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in c:\\users\\marji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.24.11)\n",
      "Requirement already satisfied: pandas in c:\\users\\marji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Collecting easyocr\n",
      "  Using cached easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\marji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\marji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\marji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\marji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\marji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\marji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Collecting torch (from easyocr)\n",
      "  Using cached torch-2.5.0-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision>=0.5 (from easyocr)\n",
      "  Using cached torchvision-0.20.0-cp312-cp312-win_amd64.whl.metadata (6.2 kB)\n",
      "Collecting opencv-python-headless (from easyocr)\n",
      "  Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\marji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from easyocr) (1.14.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\marji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from easyocr) (10.4.0)\n",
      "Collecting scikit-image (from easyocr)\n",
      "  Using cached scikit_image-0.24.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: python-bidi in c:\\users\\marji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from easyocr) (0.6.3)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\marji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from easyocr) (6.0.2)\n",
      "Requirement already satisfied: Shapely in c:\\users\\marji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from easyocr) (2.0.6)\n",
      "Requirement already satisfied: pyclipper in c:\\users\\marji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from easyocr) (1.3.0.post6)\n",
      "Requirement already satisfied: ninja in c:\\users\\marji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from easyocr) (1.11.1.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\marji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\marji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting filelock (from torch->easyocr)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\marji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->easyocr) (4.12.2)\n",
      "Collecting networkx (from torch->easyocr)\n",
      "  Using cached networkx-3.4.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\marji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->easyocr) (3.1.4)\n",
      "Collecting fsspec (from torch->easyocr)\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\marji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->easyocr) (74.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\marji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->easyocr) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\marji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch->easyocr) (1.3.0)\n",
      "Collecting imageio>=2.33 (from scikit-image->easyocr)\n",
      "  Using cached imageio-2.36.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\marji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image->easyocr) (2024.9.20)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\marji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image->easyocr) (24.1)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image->easyocr)\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\marji\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch->easyocr) (2.1.5)\n",
      "Using cached easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
      "Using cached torchvision-0.20.0-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "Using cached torch-2.5.0-cp312-cp312-win_amd64.whl (203.1 MB)\n",
      "Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Using cached scikit_image-0.24.0-cp312-cp312-win_amd64.whl (12.9 MB)\n",
      "Using cached imageio-2.36.0-py3-none-any.whl (315 kB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Using cached networkx-3.4.1-py3-none-any.whl (1.7 MB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Installing collected packages: opencv-python-headless, networkx, lazy-loader, imageio, fsspec, filelock, torch, scikit-image, torchvision, easyocr\n",
      "Successfully installed easyocr-1.7.2 filelock-3.16.1 fsspec-2024.9.0 imageio-2.36.0 lazy-loader-0.4 networkx-3.4.1 opencv-python-headless-4.10.0.84 scikit-image-0.24.0 torch-2.5.0 torchvision-0.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts imageio_download_bin.exe and imageio_remove_bin.exe are installed in 'C:\\Users\\marji\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe, torchfrtrace.exe and torchrun.exe are installed in 'C:\\Users\\marji\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script easyocr.exe is installed in 'C:\\Users\\marji\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install pymupdf pandas easyocr openpyxl opencv-python --user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58eab6a0-6b3a-47b1-8df6-3cc635e3569c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% CompleteExtracted text from image (page 1): \n",
      "Extracted text from image (page 1): \n",
      "Extracted text from image (page 1): SWipe Ab Bvsiness koro tension free\n",
      "Data successfully extracted and saved to 'invoice_data.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import easyocr\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Initialize the OCR reader (EasyOCR)\n",
    "reader = easyocr.Reader(['en'])  # Specify the language for OCR (e.g., English)\n",
    "\n",
    "# Load PDF\n",
    "pdf_path = \"test2.pdf\"  # Use your uploaded file path\n",
    "\n",
    "# Initialize lists to store extracted data\n",
    "items = []\n",
    "total_price = None\n",
    "customer_details = None\n",
    "invoice_details = None\n",
    "\n",
    "# Open the PDF\n",
    "pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "# Loop through each page\n",
    "for page_num in range(len(pdf_document)):\n",
    "    page = pdf_document.load_page(page_num)\n",
    "    text = page.get_text(\"text\")\n",
    "\n",
    "    # Extract customer details and invoice details from text\n",
    "    if not customer_details:\n",
    "        customer_match = re.search(r\"Customer Details:\\n(.+)\", text)\n",
    "        if customer_match:\n",
    "            customer_details = customer_match.group(1)\n",
    "\n",
    "    if not invoice_details:\n",
    "        invoice_match = re.search(r\"Invoice #:\\s*(.+)\\s*Invoice Date:\\s*(.+)\", text)\n",
    "        if invoice_match:\n",
    "            invoice_number = invoice_match.group(1)\n",
    "            invoice_date = invoice_match.group(2)\n",
    "            invoice_details = {\"Invoice #\": invoice_number, \"Invoice Date\": invoice_date}\n",
    "\n",
    "    # Extract items, their prices, and total price from text\n",
    "    item_pattern = re.compile(r\"(\\d)\\s+(.+?)\\s+([\\d.,]+)\\s+([\\d.,]+)\\s+([\\d.,]+)\")\n",
    "    for match in item_pattern.finditer(text):\n",
    "        item_no, item_name, rate, qty, amount = match.groups()\n",
    "        items.append({\"Item No\": item_no, \"Item\": item_name, \"Rate\": rate, \"Qty\": qty, \"Amount\": amount})\n",
    "\n",
    "    # Extract total price\n",
    "    total_match = re.search(r\"Total\\s₹([\\d.,]+)\", text)\n",
    "    if total_match:\n",
    "        total_price = total_match.group(1)\n",
    "\n",
    "    # If images are present, extract them and apply OCR using EasyOCR\n",
    "    for img_index, img in enumerate(page.get_images(full=True)):\n",
    "        xref = img[0]\n",
    "        base_image = pdf_document.extract_image(xref)\n",
    "        image_bytes = base_image[\"image\"]\n",
    "        img_ext = base_image[\"ext\"]\n",
    "        img = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "        # Convert the image to a NumPy array\n",
    "        img_np = np.array(img)\n",
    "\n",
    "        # Apply OCR to the image using EasyOCR\n",
    "        result = reader.readtext(img_np)\n",
    "\n",
    "        # Combine the OCR text result into a single string\n",
    "        ocr_text = \" \".join([res[1] for res in result])\n",
    "        print(f\"Extracted text from image (page {page_num + 1}): {ocr_text}\")\n",
    "\n",
    "# Create a pandas DataFrame for the items\n",
    "df_items = pd.DataFrame(items)\n",
    "\n",
    "# Add customer, invoice, and total price details to the DataFrame\n",
    "df_summary = pd.DataFrame({\n",
    "    \"Customer Details\": [customer_details],\n",
    "    \"Invoice #\": [invoice_details[\"Invoice #\"]],\n",
    "    \"Invoice Date\": [invoice_details[\"Invoice Date\"]],\n",
    "    \"Total Price\": [total_price]\n",
    "})\n",
    "\n",
    "# Write both data to an Excel file\n",
    "with pd.ExcelWriter(\"invoice_data.xlsx\") as writer:\n",
    "    df_items.to_excel(writer, sheet_name=\"Items\", index=False)\n",
    "    df_summary.to_excel(writer, sheet_name=\"Summary\", index=False)\n",
    "\n",
    "print(\"Data successfully extracted and saved to 'invoice_data.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "273a1dee-91ed-4b98-abba-5973818a9beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text from image (page 1): \n",
      "Extracted text from image (page 1): \n",
      "Extracted text from image (page 1): SWipe Ab Bvsiness koro tension free\n",
      "Data successfully extracted and saved to 'invoice_data_1.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "import re\n",
    "import easyocr\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the OCR reader (EasyOCR)\n",
    "reader = easyocr.Reader(['en'])  # Specify the language for OCR (e.g., English)\n",
    "\n",
    "# Load PDF\n",
    "pdf_path = \"test2.pdf\"  # Use your uploaded file path\n",
    "\n",
    "# Initialize lists to store extracted data\n",
    "items = []\n",
    "customer_details = None\n",
    "invoice_details = None\n",
    "total_price = None\n",
    "\n",
    "# Regular expression patterns for table columns\n",
    "item_pattern = re.compile(r\"(\\d+)\\s+(.+?)\\s+([\\d.,]+)\\s+([\\d.,]+)\\s+([\\d.,]+)\\s+([\\d.,]+)\\s+([\\d.,]+)\")\n",
    "\n",
    "# Open the PDF\n",
    "pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "# Loop through each page\n",
    "for page_num in range(len(pdf_document)):\n",
    "    page = pdf_document.load_page(page_num)\n",
    "    text = page.get_text(\"text\")\n",
    "\n",
    "    # Extract customer details and invoice details from text\n",
    "    if not customer_details:\n",
    "        customer_match = re.search(r\"Customer Details:\\n(.+)\", text)\n",
    "        if customer_match:\n",
    "            customer_details = customer_match.group(1)\n",
    "\n",
    "    if not invoice_details:\n",
    "        invoice_match = re.search(r\"Invoice #:\\s*(.+)\\s*Invoice Date:\\s*(.+)\", text)\n",
    "        if invoice_match:\n",
    "            invoice_number = invoice_match.group(1)\n",
    "            invoice_date = invoice_match.group(2)\n",
    "            invoice_details = {\"Invoice #\": invoice_number, \"Invoice Date\": invoice_date}\n",
    "\n",
    "    # Extract items table\n",
    "    for match in item_pattern.finditer(text):\n",
    "        item_no, item_name, rate_item, qty, taxable_value, tax_amount, amount = match.groups()\n",
    "        items.append({\n",
    "            \"Item No\": item_no,\n",
    "            \"Item\": item_name,\n",
    "            \"Rate/Item\": rate_item,\n",
    "            \"Qty\": qty,\n",
    "            \"Taxable Value\": taxable_value,\n",
    "            \"Tax Amount\": tax_amount,\n",
    "            \"Amount\": amount\n",
    "        })\n",
    "\n",
    "    # Extract total price\n",
    "    total_match = re.search(r\"Total\\s₹([\\d.,]+)\", text)\n",
    "    if total_match:\n",
    "        total_price = total_match.group(1)\n",
    "\n",
    "    # If images are present, extract them and apply OCR using EasyOCR\n",
    "    for img_index, img in enumerate(page.get_images(full=True)):\n",
    "        xref = img[0]\n",
    "        base_image = pdf_document.extract_image(xref)\n",
    "        image_bytes = base_image[\"image\"]\n",
    "        img_ext = base_image[\"ext\"]\n",
    "        img = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "        # Convert the image to a NumPy array\n",
    "        img_np = np.array(img)\n",
    "\n",
    "        # Apply OCR to the image using EasyOCR\n",
    "        result = reader.readtext(img_np)\n",
    "\n",
    "        # Combine the OCR text result into a single string\n",
    "        ocr_text = \" \".join([res[1] for res in result])\n",
    "        print(f\"Extracted text from image (page {page_num + 1}): {ocr_text}\")\n",
    "\n",
    "# Create a pandas DataFrame for the items\n",
    "df_items = pd.DataFrame(items)\n",
    "\n",
    "# Add customer, invoice, and total price details as a new row in the DataFrame\n",
    "df_summary = pd.DataFrame({\n",
    "    \"Customer Details\": [customer_details],\n",
    "    \"Invoice #\": [invoice_details[\"Invoice #\"]],\n",
    "    \"Invoice Date\": [invoice_details[\"Invoice Date\"]],\n",
    "    \"Total Price\": [total_price]\n",
    "})\n",
    "\n",
    "# Write all data into a single Excel sheet\n",
    "with pd.ExcelWriter(\"invoice_data.xlsx\") as writer:\n",
    "    df_items.to_excel(writer, sheet_name=\"Invoice\", index=False, startrow=0)\n",
    "    \n",
    "    # Writing summary data below the table\n",
    "    df_summary.to_excel(writer, sheet_name=\"Invoice\", index=False, startrow=len(df_items) + 3)\n",
    "\n",
    "print(\"Data successfully extracted and saved to 'invoice_data_1.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e3651c1-c5b4-48fc-9684-f0bf7feffcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text from image (page 1): \n",
      "Extracted text from image (page 1): \n",
      "Extracted text from image (page 1): SWipe Ab Bvsiness koro tension free\n",
      "No items found in the table.\n",
      "Data successfully extracted and saved to 'invoice_data.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "import re\n",
    "import easyocr\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the OCR reader (EasyOCR)\n",
    "reader = easyocr.Reader(['en'])  # Specify the language for OCR (e.g., English)\n",
    "\n",
    "# Load PDF\n",
    "pdf_path = \"test2.pdf\"  # Use your uploaded file path\n",
    "\n",
    "# Initialize lists to store extracted data\n",
    "items = []\n",
    "customer_details = None\n",
    "invoice_details = None\n",
    "total_price = None\n",
    "\n",
    "# Refined regular expression pattern for table extraction\n",
    "item_pattern = re.compile(r\"(\\d+)\\s+([A-Za-z0-9\\-\\s]+)\\s+([\\d.,]+)\\s+([\\d.,]+)\\s+([\\d.,]+)\\s+([\\d.,]+)\\s+([\\d.,]+)\")\n",
    "\n",
    "# Open the PDF\n",
    "pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "# Loop through each page\n",
    "for page_num in range(len(pdf_document)):\n",
    "    page = pdf_document.load_page(page_num)\n",
    "    text = page.get_text(\"text\")\n",
    "\n",
    "    # Extract customer details and invoice details from text\n",
    "    if not customer_details:\n",
    "        customer_match = re.search(r\"Customer Details:\\n(.+)\", text)\n",
    "        if customer_match:\n",
    "            customer_details = customer_match.group(1)\n",
    "\n",
    "    if not invoice_details:\n",
    "        invoice_match = re.search(r\"Invoice #:\\s*(.+)\\s*Invoice Date:\\s*(.+)\", text)\n",
    "        if invoice_match:\n",
    "            invoice_number = invoice_match.group(1)\n",
    "            invoice_date = invoice_match.group(2)\n",
    "            invoice_details = {\"Invoice #\": invoice_number, \"Invoice Date\": invoice_date}\n",
    "\n",
    "    # Extract items table\n",
    "    for match in item_pattern.finditer(text):\n",
    "        item_no, item_name, rate_item, qty, taxable_value, tax_amount, amount = match.groups()\n",
    "        items.append({\n",
    "            \"Item No\": item_no,\n",
    "            \"Item\": item_name.strip(),\n",
    "            \"Rate/Item\": rate_item,\n",
    "            \"Qty\": qty,\n",
    "            \"Taxable Value\": taxable_value,\n",
    "            \"Tax Amount\": tax_amount,\n",
    "            \"Amount\": amount\n",
    "        })\n",
    "\n",
    "    # Extract total price\n",
    "    total_match = re.search(r\"Total\\s₹([\\d.,]+)\", text)\n",
    "    if total_match:\n",
    "        total_price = total_match.group(1)\n",
    "\n",
    "    # If images are present, extract them and apply OCR using EasyOCR\n",
    "    for img_index, img in enumerate(page.get_images(full=True)):\n",
    "        xref = img[0]\n",
    "        base_image = pdf_document.extract_image(xref)\n",
    "        image_bytes = base_image[\"image\"]\n",
    "        img_ext = base_image[\"ext\"]\n",
    "        img = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "        # Convert the image to a NumPy array\n",
    "        img_np = np.array(img)\n",
    "\n",
    "        # Apply OCR to the image using EasyOCR\n",
    "        result = reader.readtext(img_np)\n",
    "\n",
    "        # Combine the OCR text result into a single string\n",
    "        ocr_text = \" \".join([res[1] for res in result])\n",
    "        print(f\"Extracted text from image (page {page_num + 1}): {ocr_text}\")\n",
    "\n",
    "# Check if items were extracted\n",
    "if items:\n",
    "    # Create a pandas DataFrame for the items\n",
    "    df_items = pd.DataFrame(items)\n",
    "else:\n",
    "    print(\"No items found in the table.\")\n",
    "\n",
    "# Add customer, invoice, and total price details as a new row in the DataFrame\n",
    "df_summary = pd.DataFrame({\n",
    "    \"Customer Details\": [customer_details],\n",
    "    \"Invoice #\": [invoice_details[\"Invoice #\"]],\n",
    "    \"Invoice Date\": [invoice_details[\"Invoice Date\"]],\n",
    "    \"Total Price\": [total_price]\n",
    "})\n",
    "\n",
    "# Write all data into a single Excel sheet\n",
    "with pd.ExcelWriter(\"invoice_data1.xlsx\") as writer:\n",
    "    if not df_items.empty:\n",
    "        df_items.to_excel(writer, sheet_name=\"Invoice\", index=False, startrow=0)\n",
    "    \n",
    "    # Writing summary data below the table\n",
    "    df_summary.to_excel(writer, sheet_name=\"Invoice\", index=False, startrow=len(df_items) + 3)\n",
    "\n",
    "print(\"Data successfully extracted and saved to 'invoice_data.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb6b517f-ce2d-49af-b2c8-322d6a900c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table extracted and saved to 'extracted_invoice_table_using_bbox.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "\n",
    "# Load the PDF\n",
    "pdf_path = \"test2.pdf\"  # Use the provided file path\n",
    "\n",
    "# Open the PDF\n",
    "pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "# Initialize a list to store rows of the table\n",
    "table_data = []\n",
    "\n",
    "# Loop through each page in the PDF\n",
    "for page_num in range(len(pdf_document)):\n",
    "    page = pdf_document.load_page(page_num)\n",
    "    \n",
    "    # Get positional information of the text in the PDF (bounding boxes)\n",
    "    blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "    \n",
    "    # Loop through each block of text\n",
    "    for block in blocks:\n",
    "        # Skip if it's not a text block\n",
    "        if \"lines\" not in block:\n",
    "            continue\n",
    "        \n",
    "        # Process each line in the block\n",
    "        for line in block[\"lines\"]:\n",
    "            row = []\n",
    "            for span in line[\"spans\"]:\n",
    "                # Append the actual text from the span to the row list\n",
    "                row.append(span[\"text\"])\n",
    "            \n",
    "            # Check if this row has the right number of columns to be part of the table\n",
    "            if len(row) >= 6:  # A heuristic: expecting at least 6 columns in the table\n",
    "                table_data.append(row)\n",
    "\n",
    "# Convert the extracted table data into a pandas DataFrame\n",
    "# Here, we expect the table to have columns like Item No, Item, Rate/Item, Qty, Taxable Value, Tax Amount, and Amount\n",
    "df_table = pd.DataFrame(table_data, columns=[\"Item No\", \"Item\", \"Rate/Item\", \"Qty\", \"Taxable Value\", \"Tax Amount\", \"Amount\"])\n",
    "\n",
    "# Save the table to an Excel file\n",
    "output_file = \"extracted_invoice_table_using_bbox.xlsx\"\n",
    "df_table.to_excel(output_file, index=False, sheet_name=\"Invoice Table\")\n",
    "\n",
    "print(f\"Table extracted and saved to '{output_file}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1365bdb-15c3-4d36-b720-393a327f7aed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "6 columns passed, passed data had 1 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:939\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_or_indexify_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:986\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[1;34m(content, columns)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[1;32m--> 986\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns passed, passed data had \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    989\u001b[0m     )\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_mi_list:\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 6 columns passed, passed data had 1 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m                 all_data\u001b[38;5;241m.\u001b[39mappend(row)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Create a DataFrame from the extracted table rows\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mItem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRate / Item\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTaxable Value\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTax Amount\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAmount\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Display the DataFrame (optional)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:851\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m--> 851\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    857\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    860\u001b[0m         arrays,\n\u001b[0;32m    861\u001b[0m         columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    865\u001b[0m     )\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:520\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    518\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[1;32m--> 520\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:845\u001b[0m, in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    842\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m    843\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[1;32m--> 845\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:942\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[1;32m--> 942\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[0;32m    945\u001b[0m     contents \u001b[38;5;241m=\u001b[39m convert_object_array(contents, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: 6 columns passed, passed data had 1 columns"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the PDF file\n",
    "pdf_path = 'test2.pdf'\n",
    "\n",
    "# Initialize a list to store all table data from the PDF\n",
    "all_data = []\n",
    "\n",
    "# Open the PDF file with pdfplumber\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    # Iterate over each page of the PDF\n",
    "    for page in pdf.pages:\n",
    "        # Extract table(s) from the current page\n",
    "        tables = page.extract_table()\n",
    "        \n",
    "        # If table(s) found, process them\n",
    "        if tables:\n",
    "            # Skip the first row (headers) and append the rest to all_data\n",
    "            for row in tables[1:]:  # [1:] skips the header row\n",
    "                all_data.append(row)\n",
    "\n",
    "# Create a DataFrame from the extracted table rows\n",
    "df = pd.DataFrame(all_data, columns=[\"Item\", \"Rate / Item\", \"Qty\", \"Taxable Value\", \"Tax Amount\", \"Amount\"])\n",
    "\n",
    "# Display the DataFrame (optional)\n",
    "print(df)\n",
    "\n",
    "# Saving the DataFrame to an Excel file\n",
    "excel_path = 'extracted_invoice_table_general.xlsx'\n",
    "df.to_excel(excel_path, index=False)\n",
    "\n",
    "print(f'Table extracted and saved to {excel_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d04011-a7a5-4471-9415-fb85892f7a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
